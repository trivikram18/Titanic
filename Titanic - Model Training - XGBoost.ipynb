{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ReadIn the training data\n",
    "titanic_train = pd.read_csv(\"titanic_train.csv\")\n",
    "print (titanic_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    ">age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    ">sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
    "\n",
    ">parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate out the target/ label from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All column names: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Training data column names: Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Training label: Survived\n"
     ]
    }
   ],
   "source": [
    "print(f'All column names: {titanic_train.columns}')\n",
    "X_train = titanic_train.copy()\n",
    "y_train = X_train.pop('Survived')\n",
    "print(f'Training data column names: {X_train.columns}')\n",
    "print(f'Training label: {y_train.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c3b88b378d4108c61a0f769befb334946f3dbf1d"
   },
   "outputs": [],
   "source": [
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if str.find(big_string, substring) != -1:\n",
    "            return substring\n",
    "    # print (big_string)\n",
    "    return np.nan\n",
    "\n",
    "def replace_titles(x):\n",
    "    title=x['salut']\n",
    "    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir']:\n",
    "        return 'Mr'\n",
    "    elif title in ['the Countess', 'Mme', 'Lady', 'Dona']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if x['Sex']=='Male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values from salut - training dataset:\n",
      " ['Mr' 'Mrs' 'Miss' 'Master' 'Don' 'Rev' 'Dr' 'Mme' 'Ms' 'Major' 'Lady'\n",
      " 'Sir' 'Mlle' 'Col' 'Capt' 'the Countess' 'Jonkheer'] \n",
      "\n",
      "salut Before:\n",
      "Mr              517\n",
      "Miss            182\n",
      "Mrs             125\n",
      "Master           40\n",
      "Dr                7\n",
      "Rev               6\n",
      "Mlle              2\n",
      "Col               2\n",
      "Major             2\n",
      "Ms                1\n",
      "the Countess      1\n",
      "Jonkheer          1\n",
      "Sir               1\n",
      "Capt              1\n",
      "Don               1\n",
      "Lady              1\n",
      "Mme               1\n",
      "Name: salut, dtype: int64 \n",
      "\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'salut'],\n",
      "      dtype='object') \n",
      "\n",
      "salut After:\n",
      "Mr        531\n",
      "Miss      185\n",
      "Mrs       135\n",
      "Master     40\n",
      "Name: salut, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>salut</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "salut  Master  Miss  Mr  Mrs\n",
       "Age                         \n",
       "62.0        0     0   3    1\n",
       "63.0        0     1   0    1\n",
       "64.0        0     0   2    0\n",
       "65.0        0     0   3    0\n",
       "66.0        0     0   1    0\n",
       "70.0        0     0   2    0\n",
       "70.5        0     0   1    0\n",
       "71.0        0     0   2    0\n",
       "74.0        0     0   1    0\n",
       "80.0        0     0   1    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Name and extract the salutation\n",
    "\n",
    "X_train['salut'] = X_train['Name'].str.split(',',expand=True)[1].str.split('.',expand=True)[0].str.strip()\n",
    "print(\"Unique values from salut - training dataset:\\n\", X_train['salut'].unique(), \"\\n\")\n",
    "\n",
    "print (\"salut Before:\")\n",
    "print (X_train['salut'].value_counts(), \"\\n\")\n",
    "\n",
    "# X_train.drop(['firstname', 'last_name', 'lastname', 'lastname1'], axis=1, inplace=True)\n",
    "print (X_train.columns, \"\\n\")\n",
    "\n",
    "X_train['salut']=X_train.apply(replace_titles, axis=1)\n",
    "print (\"salut After:\")\n",
    "print (X_train['salut'].value_counts())\n",
    "\n",
    "Age_salut = pd.crosstab(X_train.Age, X_train.salut)\n",
    "Age_salut.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing data to fill in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values for Age before imputation:  177\n",
      "Null values for Age after imputation:  0\n"
     ]
    }
   ],
   "source": [
    "# Imputing Age - We are using the 'salut' feature to group the respondent to impute the age\n",
    "print (\"Null values for Age before imputation: \", X_train['Age'].isnull().sum())\n",
    "X_train['Age'] = X_train.groupby('salut').Age.transform(lambda x: x.fillna(x.mean()))\n",
    "print (\"Null values for Age after imputation: \", X_train['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values for Cabin before imputation:  687\n",
      "Value Counts of Cabin - Before\n",
      "NaN            687\n",
      "G6               4\n",
      "C23 C25 C27      4\n",
      "B96 B98          4\n",
      "F2               3\n",
      "              ... \n",
      "A6               1\n",
      "B78              1\n",
      "B80              1\n",
      "A16              1\n",
      "A19              1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "Value Counts of Cabin - After\n",
      "Null           687\n",
      "B96 B98          4\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "F2               3\n",
      "              ... \n",
      "C99              1\n",
      "A6               1\n",
      "B78              1\n",
      "B80              1\n",
      "A19              1\n",
      "Name: Cabin, Length: 148, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imputing Cabin - This cannot be imputed as there is no logic and hence we fill the NAs with 'Null' string\n",
    "print(\"Null values for Cabin before imputation: \", X_train['Cabin'].isnull().sum())\n",
    "\n",
    "print(\"Value Counts of Cabin - Before\")\n",
    "print (X_train['Cabin'].value_counts(dropna = False))\n",
    "\n",
    "X_train['Cabin'] = X_train['Cabin'].fillna('Null')\n",
    "\n",
    "print(\"Value Counts of Cabin - After\")\n",
    "print (X_train['Cabin'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values after imputation: \n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "salut          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imputing the whole dataset just in case there are any furhter missing values\n",
    "X_train = X_train.fillna(method='ffill').fillna(method='bfill')\n",
    "print(\"Null values after imputation: \")\n",
    "print(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Null    687\n",
       "C        59\n",
       "B        47\n",
       "E        33\n",
       "D        33\n",
       "A        15\n",
       "F        12\n",
       "G         4\n",
       "T         1\n",
       "Name: Deck, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deck\n",
    "cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Null']\n",
    "X_train['Deck']=X_train['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "\n",
    "X_train['Deck'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     537\n",
      "2     161\n",
      "3     102\n",
      "4      29\n",
      "6      22\n",
      "5      15\n",
      "7      12\n",
      "11      7\n",
      "8       6\n",
      "Name: FamilySize, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Family Size and Fare per Passenger\n",
    "X_train['FamilySize'] = X_train['SibSp'] + X_train['Parch'] + 1\n",
    "# X_train['FarePerPassenger'] = X_train['Fare']/(X_train['FamilySize'])\n",
    "\n",
    "print(X_train['FamilySize'].value_counts())\n",
    "# print()\n",
    "# print(X_train['FarePerPassenger'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv(\"Titanic_Train_Processed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Categorical and String features into Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "eab93f8f93e80eda4dc0cb408eeb64e2b5ae98b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training dataset after One Hot Encoding:  (891, 855)\n",
      "    Age  SibSp  Parch     Fare  FamilySize  Pclass_1  Pclass_2  Pclass_3  \\\n",
      "0  22.0      1      0   7.2500           2         0         0         1   \n",
      "1  38.0      1      0  71.2833           2         1         0         0   \n",
      "2  26.0      0      0   7.9250           1         0         0         1   \n",
      "3  35.0      1      0  53.1000           2         1         0         0   \n",
      "4  35.0      0      0   8.0500           1         0         0         1   \n",
      "\n",
      "   Sex_female  Sex_male  ...  Ticket_WE/P 5735  Deck_A  Deck_B  Deck_C  \\\n",
      "0           0         1  ...                 0       0       0       0   \n",
      "1           1         0  ...                 0       0       0       1   \n",
      "2           1         0  ...                 0       0       0       0   \n",
      "3           1         0  ...                 0       0       0       1   \n",
      "4           0         1  ...                 0       0       0       0   \n",
      "\n",
      "   Deck_D  Deck_E  Deck_F  Deck_G  Deck_Null  Deck_T  \n",
      "0       0       0       0       0          1       0  \n",
      "1       0       0       0       0          0       0  \n",
      "2       0       0       0       0          1       0  \n",
      "3       0       0       0       0          0       0  \n",
      "4       0       0       0       0          1       0  \n",
      "\n",
      "[5 rows x 855 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop features which are unique across respondents as they are not useful\n",
    "X_train.drop(['Name', 'PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "# One Hot Encoding - To convert categorical to binary data\n",
    "X_train_dummies = pd.get_dummies(X_train, columns=['Pclass', 'Sex', 'Cabin', 'Embarked', 'salut', 'Ticket', 'Deck'])\n",
    "\n",
    "print (\"Shape of training dataset after One Hot Encoding: \", X_train_dummies.shape)\n",
    "print (X_train_dummies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data - ReadIn, Preprocess, Imputing, Feature Engineering and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReadIn the test data\n",
    "\n",
    "titanic_test = pd.read_csv(\"titanic_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values from salut - test dataset:\n",
      " ['Mr' 'Mrs' 'Miss' 'Master' 'Ms' 'Col' 'Rev' 'Dr' 'Dona']\n",
      "salut Before:\n",
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Rev         2\n",
      "Col         2\n",
      "Ms          1\n",
      "Dr          1\n",
      "Dona        1\n",
      "Name: salut, dtype: int64\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'salut'],\n",
      "      dtype='object')\n",
      "salut After:\n",
      "Mr        244\n",
      "Miss       79\n",
      "Mrs        74\n",
      "Master     21\n",
      "Name: salut, dtype: int64\n",
      "salut  Master  Miss  Mr  Mrs\n",
      "Age                         \n",
      "0.17        0     1   0    0\n",
      "0.33        1     0   0    0\n",
      "0.75        1     0   0    0\n",
      "0.83        1     0   0    0\n",
      "0.92        0     1   0    0\n",
      "1.00        0     3   0    0\n",
      "salut  Master  Miss  Mr  Mrs\n",
      "Age                         \n",
      "61.0        0     0   2    0\n",
      "62.0        0     0   1    0\n",
      "63.0        0     0   1    1\n",
      "64.0        0     0   1    2\n",
      "67.0        0     0   1    0\n",
      "76.0        0     0   0    1\n"
     ]
    }
   ],
   "source": [
    "X_test = titanic_test.copy()\n",
    "\n",
    "# Split Name and extract the salutation\n",
    "X_test['salut'] = X_test['Name'].str.split(',',expand=True)[1].str.split('.',expand=True)[0].str.strip()\n",
    "print(\"Unique values from salut - test dataset:\\n\", X_test['salut'].unique())\n",
    "\n",
    "print (\"salut Before:\")\n",
    "print (X_test['salut'].value_counts())\n",
    "\n",
    "print (X_test.columns)\n",
    "\n",
    "X_test['salut']=X_test.apply(replace_titles, axis=1)\n",
    "\n",
    "print (\"salut After:\")\n",
    "print (X_test['salut'].value_counts())\n",
    "\n",
    "Age_salut_test = pd.crosstab(X_test.Age, X_test.salut)\n",
    "print(Age_salut_test.head(6))\n",
    "print(Age_salut_test.tail(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "add3b30e-ceda-4171-ad58-38140f50038b",
    "_uuid": "e899a2126368a63a402a685ebfa87e3eb5e71613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values for Age before imputation:  86\n",
      "Null values for Age after imputation:  0 \n",
      "\n",
      "Null values for Fare before imputation:  1\n",
      "Null values for Fare after imputation:  0 \n",
      "\n",
      "Null values for Cabin before imputation:  0\n",
      "Null values for Cabin after imputation:  0 \n",
      "\n",
      "Null values after imputation: \n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "salut          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imputing missing values - Test Data\n",
    "print (\"Null values for Age before imputation: \", X_test['Age'].isnull().sum())\n",
    "X_test['Age'] = X_test.groupby('salut').Age.transform(lambda x: x.fillna(x.mean()))\n",
    "print (\"Null values for Age after imputation: \", X_test['Age'].isnull().sum(), \"\\n\")\n",
    "\n",
    "print (\"Null values for Fare before imputation: \", X_test['Fare'].isnull().sum())\n",
    "X_test['Fare'] = X_test.groupby('Pclass').Fare.transform(lambda x: x.fillna(x.median()))\n",
    "print (\"Null values for Fare after imputation: \", X_test['Fare'].isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"Null values for Cabin before imputation: \", X_train['Cabin'].isnull().sum())\n",
    "X_test['Cabin'] = X_test['Cabin'].fillna('Null')\n",
    "print(\"Null values for Cabin after imputation: \", X_train['Cabin'].isnull().sum(), \"\\n\")\n",
    "\n",
    "# Imputing the whole dataset just in case there are any furhter missing values\n",
    "X_test = X_test.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "print(\"Null values after imputation: \")\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null    327\n",
      "C        35\n",
      "B        18\n",
      "D        13\n",
      "E        11\n",
      "A         7\n",
      "F         6\n",
      "G         1\n",
      "Name: Deck, dtype: int64 \n",
      "\n",
      "1     253\n",
      "2      74\n",
      "3      57\n",
      "4      14\n",
      "5       7\n",
      "11      4\n",
      "7       4\n",
      "6       3\n",
      "8       2\n",
      "Name: FamilySize, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Feature Engineering\n",
    "# Deck\n",
    "X_test['Deck']=X_test['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "print(X_test['Deck'].value_counts(), \"\\n\")\n",
    "\n",
    "# Family Size and Fare per Passenger\n",
    "X_test['FamilySize'] = X_test['SibSp'] + X_test['Parch'] + 1\n",
    "# X_test['FarePerPassenger'] = X_test['Fare']/(X_test['FamilySize'] + 1)\n",
    "\n",
    "print(X_test['FamilySize'].value_counts(), \"\\n\")\n",
    "# print()\n",
    "# print(X_test['FarePerPassenger'].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test dataset after One Hot Encoding:  (418, 466)\n",
      "                                           Name   Age  SibSp  Parch     Fare  \\\n",
      "0                              Kelly, Mr. James  34.5      0      0   7.8292   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  47.0      1      0   7.0000   \n",
      "2                     Myles, Mr. Thomas Francis  62.0      0      0   9.6875   \n",
      "3                              Wirz, Mr. Albert  27.0      0      0   8.6625   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0      1      1  12.2875   \n",
      "\n",
      "   FamilySize  Pclass_1  Pclass_2  Pclass_3  Sex_female  ...  \\\n",
      "0           1         0         0         1           0  ...   \n",
      "1           2         0         0         1           1  ...   \n",
      "2           1         0         1         0           0  ...   \n",
      "3           1         0         0         1           0  ...   \n",
      "4           3         0         0         1           1  ...   \n",
      "\n",
      "   Ticket_W./C. 6608  Ticket_W.E.P. 5734  Deck_A  Deck_B  Deck_C  Deck_D  \\\n",
      "0                  0                   0       0       0       0       0   \n",
      "1                  0                   0       0       0       0       0   \n",
      "2                  0                   0       0       0       0       0   \n",
      "3                  0                   0       0       0       0       0   \n",
      "4                  0                   0       0       0       0       0   \n",
      "\n",
      "   Deck_E  Deck_F  Deck_G  Deck_Null  \n",
      "0       0       0       0          1  \n",
      "1       0       0       0          1  \n",
      "2       0       0       0          1  \n",
      "3       0       0       0          1  \n",
      "4       0       0       0          1  \n",
      "\n",
      "[5 rows x 466 columns]\n"
     ]
    }
   ],
   "source": [
    "## Converting Categorical and String features into Numeric\n",
    "\n",
    "# Drop features which are unique across respondents as they are not useful\n",
    "X_test.drop(['PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "# One Hot Encoding - To convert categorical to binary data\n",
    "X_test_dummies = pd.get_dummies(X_test, columns=['Pclass', 'Sex', 'Cabin', 'Embarked', 'salut', 'Ticket', 'Deck'])\n",
    "print (\"Shape of test dataset after One Hot Encoding: \", X_test_dummies.shape)\n",
    "print (X_test_dummies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training dataset after One Hot Encoding:  (891, 855)\n",
      "Shape of test dataset after One Hot Encoding:  (418, 466)\n"
     ]
    }
   ],
   "source": [
    "print (\"Shape of training dataset after One Hot Encoding: \", X_train_dummies.shape)\n",
    "print (\"Shape of test dataset after One Hot Encoding: \", X_test_dummies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "3ef4c4c0-8a74-4685-8e78-ceea5092a7c5",
    "_uuid": "6c68eac37e1441787ae3f9234464e3bfc303b037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 855)\n",
      "(418, 855)\n",
      "Age           0\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          0\n",
      "FamilySize    0\n",
      "             ..\n",
      "Deck_E        0\n",
      "Deck_F        0\n",
      "Deck_G        0\n",
      "Deck_Null     0\n",
      "Deck_T        0\n",
      "Length: 855, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Align the Train and Test datset for One Hot Encoding \n",
    "X_train_final, X_test_final = X_train_dummies.align(X_test_dummies, join='left', axis=1)\n",
    "print (X_train_final.shape)\n",
    "print (X_test_final.shape)\n",
    "\n",
    "for col in (col for col in X_test_final.columns if X_test_final[col].isnull().any()):\n",
    "    X_test_final[col] = 0\n",
    "\n",
    "print(X_test_final.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final_description = X_train_final.describe().T\n",
    "X_test_final_description = X_test_final.describe().T\n",
    "\n",
    "X_train_final_description.to_csv(\"X_train_final_description.csv\")\n",
    "X_test_final_description.to_csv(\"X_test_final_description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X_train_standard_scaled = standard_scaler.fit_transform(X_train_final)\n",
    "# X_train_standard_scaled.mean(axis=0)\n",
    "X_test_standard_scaled = standard_scaler.fit_transform(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "682c5d7a-17c5-428a-8a5f-c6522dfec54d",
    "_uuid": "9062f190af0e65f91964fae8118adcd21c204c13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 855)\n",
      "(268, 855)\n",
      "All: [61.61616162 38.38383838]\n",
      "Training: [61.63723917 38.36276083]\n",
      "Test: [61.56716418 38.43283582]\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and evaluation data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X, val_X, y, val_y = train_test_split(X_train_final, y_train, train_size=0.7, test_size=0.3, random_state=123, stratify=y_train)\n",
    "\n",
    "# Applying scaled data\n",
    "X, val_X, y, val_y = train_test_split(X_train_standard_scaled, y_train, train_size=0.7, test_size=0.3, random_state=123, stratify=y_train)\n",
    "\n",
    "print (X.shape)\n",
    "print (val_X.shape)\n",
    "print('All:', np.bincount(y_train) / float(len(y_train)) * 100.0)\n",
    "print('Training:', np.bincount(y) / float(len(y)) * 100.0)\n",
    "print('Test:', np.bincount(val_y) / float(len(val_y)) * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "print(xgb.__version__)\n",
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters:\n",
      "{'objective': 'binary:logistic', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 1, 'gpu_id': -1, 'importance_type': 'gain', 'interaction_constraints': None, 'learning_rate': 0.05, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 400, 'n_jobs': 0, 'num_parallel_tree': 1, 'random_state': 41, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': None, 'validate_parameters': False, 'verbosity': None, 'early_stopping_rounds': 5} \n",
      "\n",
      "Count for validation data - actual:  [165 103]\n",
      "Count for validation data - prediction:  [177  91] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_XGB_sklearn = XGBClassifier(n_estimators=400, learning_rate=0.05, early_stopping_rounds=5, max_depth=3, min_child_weight=1, \n",
    "                          gamma=1, subsample=1, colsample_bytree=1, booster='gbtree', random_state=41)\n",
    "model_XGB_sklearn.fit(X, y)\n",
    "\n",
    "print(\"Model Parameters:\")\n",
    "print(model_XGB_sklearn.get_params(), \"\\n\")\n",
    "\n",
    "predictions = model_XGB_sklearn.predict(val_X)\n",
    "predict_proba = model_XGB_sklearn.predict_proba(val_X)\n",
    "\n",
    "print (\"Count for validation data - actual: \", np.bincount(val_y))\n",
    "print (\"Count for validation data - prediction: \", np.bincount(predictions), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters:\n",
      "0.33819258\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "Count for validation data - actual:  [165 103]\n",
      "Count for validation data - prediction:  [268] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "#         'n_estimators': 400,\n",
    "        'learning_rate': 0.05,\n",
    "#         'early_stopping_rounds': 5,\n",
    "        'max_depth': 3,\n",
    "        'min_child_weight': 1,\n",
    "        'gamma': 1,\n",
    "        'subsample': 1,\n",
    "        'colsample_bytree': 1,\n",
    "        'random_state': 41\n",
    "        }\n",
    "steps = 10\n",
    "\n",
    "D_train = xgb.DMatrix(X, label=y)\n",
    "D_test = xgb.DMatrix(val_X, label=val_y)\n",
    "\n",
    "model_XGB = xgb.train(params, D_train, steps)\n",
    "\n",
    "print(\"Model Parameters:\")\n",
    "# print(model_XGB.get_params(), \"\\n\")\n",
    "\n",
    "predictions = model_XGB.predict(D_test)\n",
    "# print(predictions.shape)\n",
    "# print(predictions.dtype)\n",
    "print(predictions[0])\n",
    "best_preds = np.asarray([np.argmax(line) for line in predictions])\n",
    "print(best_preds)\n",
    "\n",
    "# predict_proba = model_XGB.predict_proba(D_test)\n",
    "\n",
    "print (\"Count for validation data - actual: \", np.bincount(val_y))\n",
    "print (\"Count for validation data - prediction: \", np.bincount(best_preds), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for training data - XGBoost:  0.9181380417335474\n",
      "Score for validation data - XGBoost:  0.832089552238806 \n",
      "\n",
      "Predictions:  [0 1 0 0 0 0] \n",
      "\n",
      "Prediction Probabilities:\n",
      " [[0.85375005 0.14624994]\n",
      " [0.00858903 0.991411  ]\n",
      " [0.86770856 0.13229144]\n",
      " [0.91932213 0.08067787]\n",
      " [0.98871756 0.01128246]\n",
      " [0.7196296  0.2803704 ]]\n"
     ]
    }
   ],
   "source": [
    "# Score\n",
    "print (\"Score for training data - XGBoost: \", model_XGB.score(X, y))\n",
    "score_val_dataset = model_XGB.score(val_X, val_y)\n",
    "print (\"Score for validation data - XGBoost: \", score_val_dataset, \"\\n\")\n",
    "\n",
    "print(\"Predictions: \", predictions[0:6], \"\\n\")\n",
    "print(\"Prediction Probabilities:\\n\", predict_proba[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "9043eb8cdacd754f94a094e38fe3adf37c01e856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for validation data - XGBoost:  0.7715736040609138\n",
      "f1_score (average=None) for validation data - XGBoost:  [0.86725664 0.7715736 ] \n",
      "\n",
      "precision_recall_fscore for validation data - XGBoost:  (array([0.84482759, 0.80851064]), array([0.89090909, 0.73786408]), array([0.86725664, 0.7715736 ]), array([165, 103], dtype=int64)) \n",
      "\n",
      "Accuracy for model XGBoost: 83.21\n",
      "Classification Report - Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       384\n",
      "           1       0.92      0.86      0.89       239\n",
      "\n",
      "    accuracy                           0.92       623\n",
      "   macro avg       0.92      0.91      0.91       623\n",
      "weighted avg       0.92      0.92      0.92       623\n",
      "\n",
      "Classification Report - Validation Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       165\n",
      "           1       0.81      0.74      0.77       103\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score, classification_report\n",
    "\n",
    "print (\"f1_score for validation data - XGBoost: \", f1_score(val_y, model_XGB.predict(val_X)))\n",
    "print (\"f1_score (average=None) for validation data - XGBoost: \", f1_score(val_y, model_XGB.predict(val_X), average=None), \"\\n\")\n",
    "\n",
    "print (\"precision_recall_fscore for validation data - XGBoost: \", precision_recall_fscore_support(val_y, model_XGB.predict(val_X)), \"\\n\")\n",
    "\n",
    "print(\"Accuracy for model XGBoost: %.2f\" % (accuracy_score(val_y, model_XGB.predict(val_X)) * 100))\n",
    "\n",
    "print(\"Classification Report - Training Data\")\n",
    "print(classification_report(y, model_XGB.predict(X)))\n",
    "\n",
    "print(\"Classification Report - Validation Data\")\n",
    "print(classification_report(val_y, model_XGB.predict(val_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying cross validation on the enire training data\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, ShuffleSplit\n",
    "\n",
    "# scores = cross_val_score(model_logistic_regression, X_train_final, y_train)\n",
    "scores = cross_val_score(model_XGB, X_train_standard_scaled, y_train)\n",
    "print(\"\\nScore for training data with default CV: \", scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "scores = cross_val_score(model_XGB, X_train_standard_scaled, y_train, cv=3)\n",
    "print(\"\\nScore for training data with CV=3: \", scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e7788a12-823e-46c4-8516-6504c630df80",
    "_uuid": "af835a1d079f47be012d4cdeaab275fc3dfea559"
   },
   "outputs": [],
   "source": [
    "# Applying cross validation by splitting the training data into training data and validation data\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, ShuffleSplit\n",
    "\n",
    "scores = cross_val_score(model_XGB, X, y)\n",
    "print(\"Score for training data with default CV: \", scores)\n",
    "print(\"Mean Score: \", np.mean(scores), \"\\n\")\n",
    "\n",
    "scores = cross_val_score(model_XGB, X, y, cv=3)\n",
    "print(\"Score for training data with CV=3: \", scores)\n",
    "print(\"Mean Score: \", np.mean(scores), \"\\n\")\n",
    "\n",
    "scores = cross_val_score(model_XGB, val_X, val_y, cv=3)\n",
    "print(\"Score for validation data with CV=3: \", scores)\n",
    "print(\"Mean Score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b2d8524c-e2f6-4d99-9ebe-5b9b0dda3b40",
    "_uuid": "369e224e3bc2e94f29c4da661999f275da399988"
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=4)\n",
    "scores = cross_val_score(model_XGB, val_X, val_y, cv=cv)\n",
    "print(\"Score for validation data with StartifiedKFold, CV=5: \", scores)\n",
    "print(\"Mean Score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "562daf63-8a3a-491a-b400-a1376c164ae5",
    "_uuid": "4473beab4bc8c184145834cee2910590d387fe27"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "# n_estimators=400, learning_rate=0.05, early_stopping_rounds=5, max_depth=3, random_state=41\n",
    "model_XGB_grid = GridSearchCV(XGBClassifier(n_estimators=400, learning_rate=0.05, early_stopping_rounds=5, random_state=41), param_grid=param_grid, cv=cv, verbose=3, n_jobs=-1)\n",
    "model_XGB_grid.fit(X, y)\n",
    "\n",
    "results_grid = model_XGB_grid.cv_results_\n",
    "\n",
    "print (\"Parameters: \", model_XGB_grid.get_params)\n",
    "\n",
    "print(\"\\nGridSearchCV best score - XGBoost: \", model_XGB_grid.best_score_)\n",
    "print(\"\\nGridSearchCV best params - XGBoost: \", model_XGB_grid.best_params_)\n",
    "print(\"\\nGridSearchCV best estimator - XGBoost: \", model_XGB_grid.best_estimator_)\n",
    "\n",
    "print (\"\\nGridSearchCV Score for validation data - XGBoost: \", model_XGB_grid.score(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Parameters:\")\n",
    "print(model_logistic_regression_grid.get_params(), \"\\n\")\n",
    "\n",
    "predictions_grid = model_logistic_regression_grid.predict(val_X)\n",
    "predict_proba_grid = model_logistic_regression_grid.predict_proba(val_X)\n",
    "\n",
    "print (\"Count for validation data - actual: \", np.bincount(val_y))\n",
    "print (\"Count for validation data - prediction-grid: \", np.bincount(predictions_grid), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score\n",
    "print (\"Score for training data - Logistic Regression: \", model_logistic_regression_grid.score(X, y))\n",
    "score_grid_val_dataset = model_logistic_regression_grid.score(val_X, val_y)\n",
    "print (\"Score for validation data - Logistic Regression: \", score_grid_val_dataset, \"\\n\")\n",
    "\n",
    "print(\"Predictions grid: \", predictions_grid[0:6], \"\\n\")\n",
    "print(\"Prediction Probabilities grid:\\n\", predict_proba_grid[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch with Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'Accuracy': 'accuracy', 'F1 Score': 'f1'}\n",
    "model_logistic_regression_grid_with_scoring = GridSearchCV(LogisticRegression(max_iter=200), param_grid=param_grid, cv=cv, verbose=3, scoring = scoring, refit=False)\n",
    "model_logistic_regression_grid_with_scoring.fit(X, y)\n",
    "results_grid_with_scoring = model_logistic_regression_grid_with_scoring.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(sklearn.metrics.SCORERS.keys())\n",
    "results_grid_with_scoring = model_logistic_regression_grid_with_scoring.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_grid_with_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
